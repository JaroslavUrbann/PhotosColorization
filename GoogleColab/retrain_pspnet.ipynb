{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "id": "EH6LvfJJq20y",
    "outputId": "bb74fa95-7e06-4eed-d510-0cea3f7f3f55"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Download dataset and models from google drive\n",
    "################################################################################\n",
    "\n",
    "!pip install PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "from google.colab import files\n",
    "import os.path\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "dataset_training = drive.CreateFile({'id': '175QZrGu2KyjKITBcePwcyFzcL1zyJWi9'})\n",
    "dataset_training.GetContentFile(\"dataset2_training_0.zip\")\n",
    "\n",
    "dataset_validation = drive.CreateFile({'id': '1Hu4bm92fmnNNPlvweKUgdaPRkL_uN74Z'})\n",
    "dataset_validation.GetContentFile(\"dataset2_validation_0.zip\")\n",
    "\n",
    "model = drive.CreateFile({'id': '1_DaND4hvVBxS_is8GCZS-JSJLiDTYHRY'})\n",
    "model.GetContentFile(\"pspnet.h5\")\n",
    "\n",
    "model = drive.CreateFile({'id': '1YpCm6bho9fNCVgY9Bh8WBaXX5OQlFqI1'})\n",
    "model.GetContentFile(\"trained_pspnet.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "v-fBEuOstQ8f",
    "outputId": "e738619b-e117-4713-a7da-6768e6266a49"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Import libraries\n",
    "################################################################################\n",
    "\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import CSVLogger, Callback\n",
    "from keras import layers\n",
    "from keras.backend import tf as ktf, eval, set_value\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ISz4oksXtS1f"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Generator and its functions\n",
    "################################################################################\n",
    "\n",
    "# returns x, y\n",
    "def batch_images(index, batch_size, image_paths, imgs, trained_model):\n",
    "    with imgs.open(image_paths[index]) as img:\n",
    "        img = Image.open(img).transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    img = img.resize((473, 473))\n",
    "\n",
    "    y = predict_segmentation(img, trained_model)\n",
    "    x = np.array(img.convert(\"L\").convert(\"RGB\")) - np.array([[[128, 128, 128]]])\n",
    "\n",
    "    return np.expand_dims(x, axis=0), y\n",
    "\n",
    "\n",
    "# Returns one-hot encoded segmentation object (w x h x 150)\n",
    "def predict_segmentation(img, trained_model):\n",
    "    data_mean = np.array([[[123.68, 116.779, 103.939]]])\n",
    "    pixel_img = np.array(img)\n",
    "    pixel_img = pixel_img - data_mean\n",
    "    bgr_img = pixel_img[:, :, ::-1]\n",
    "    segmented_img = trained_model.predict(np.expand_dims(bgr_img, axis=0))\n",
    "    return segmented_img\n",
    "\n",
    "\n",
    "# Yields batches of x and y values\n",
    "def generator_fn(batch_size, images_path, trained_model, validation=False):\n",
    "    with zipfile.ZipFile(images_path) as imgs:\n",
    "        image_paths = imgs.infolist()\n",
    "        n_images = len(image_paths)\n",
    "        i = 0\n",
    "        while True:\n",
    "            if i + batch_size > n_images:\n",
    "                i = 0\n",
    "            if validation and i + batch_size > 256:\n",
    "                i = 0\n",
    "            x, y = batch_images(i, batch_size, image_paths, imgs, trained_model)\n",
    "            i += batch_size\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JtVEUodN9Rch"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Loading, training and saving model\n",
    "################################################################################\n",
    "\n",
    "# custom pspnet layer\n",
    "class Interp(layers.Layer):\n",
    "\n",
    "    def __init__(self, new_size, **kwargs):\n",
    "        self.new_size = new_size\n",
    "        super(Interp, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Interp, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        new_height, new_width = self.new_size\n",
    "        resized = ktf.image.resize_images(inputs, [new_height, new_width],\n",
    "                                          align_corners=True)\n",
    "        return resized\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple([None, self.new_size[0], self.new_size[1], input_shape[3]])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Interp, self).get_config()\n",
    "        config['new_size'] = self.new_size\n",
    "        return config\n",
    "\n",
    "\n",
    "# Returns pspnet\n",
    "def load_trained_model(path):\n",
    "    trained_model = load_model(path, custom_objects={'Interp': Interp})\n",
    "    trained_model._make_predict_function()\n",
    "    return trained_model\n",
    "\n",
    "  \n",
    "# Class for saving and uploading model & csv logger\n",
    "class Upload2Drive(Callback):\n",
    "    def __init__(self, model_name, n_epochs):\n",
    "        self.model_name = model_name\n",
    "        self.n_epochs = n_epochs\n",
    "        self.model_checkpoint = drive.CreateFile({\"title\": self.model_name + \".h5\",\n",
    "                                                \"parents\": [{\"kind\": \"drive#childList\",\n",
    "                                                             \"id\": \"1b4yDZuEjuCDuEKybgyHBWX85ovIbjGAX\"}]})\n",
    "        self.model_log = drive.CreateFile({\"title\": self.model_name + \".csv\",\n",
    "                                          \"parents\": [{\"kind\": \"drive#childList\",\n",
    "                                                       \"id\": \"1b4yDZuEjuCDuEKybgyHBWX85ovIbjGAX\"}]})\n",
    "  \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        try:\n",
    "            if gauth.access_token_expired:\n",
    "                gauth.Refresh()\n",
    "        except:\n",
    "            print(\"refresh failed\")\n",
    "        if True or epoch / self.n_epochs > 0.4:\n",
    "            try:\n",
    "                self.model.save(self.model_name + \".h5\", overwrite=True)\n",
    "                self.model_checkpoint.SetContentFile(self.model_name + \".h5\")\n",
    "                self.model_log.SetContentFile(self.model_name + \".csv\")\n",
    "            except:\n",
    "                print(\"save failed\")\n",
    "\n",
    "            try:\n",
    "                self.model_checkpoint.Upload()\n",
    "                self.model_log.Upload()\n",
    "            except:\n",
    "                print(\"upload checkpoint failed\")\n",
    "\n",
    "# Returns list of callbacks\n",
    "def callbacks(model_name, n_epochs):\n",
    "    cb = list()\n",
    "    cb.append(CSVLogger(model_name + \".csv\"))\n",
    "    cb.append(Upload2Drive(model_name, n_epochs))\n",
    "    return cb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1427
    },
    "colab_type": "code",
    "id": "sYVphuxt9wrP",
    "outputId": "58cf5a73-e611-48f2-f33c-929309bb2251"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Main\n",
    "################################################################################\n",
    "\n",
    "model_name = \"pspnet_8\"\n",
    "batch_size = 1\n",
    "batches_per_epoch = 4672\n",
    "n_epochs = 10\n",
    "batches_per_validation = 256\n",
    "\n",
    "trained_model = load_trained_model(\"trained_pspnet.h5\")\n",
    "model = load_trained_model(\"pspnet.h5\")\n",
    "\n",
    "training_data_fn = generator_fn(batch_size, \"dataset2_training_0.zip\", trained_model)\n",
    "validation_data_fn = generator_fn(batch_size, \"dataset2_validation_0.zip\", trained_model, validation=True)\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit_generator(training_data_fn,\n",
    "                    epochs=n_epochs,\n",
    "                    steps_per_epoch=batches_per_epoch,\n",
    "                    callbacks=callbacks(model_name, n_epochs),\n",
    "                    validation_data=validation_data_fn,\n",
    "                    validation_steps=batches_per_validation,\n",
    "                    verbose=2,\n",
    "                    max_queue_size=30)\n",
    "\n",
    "print(\"Training took: \" + str(time.time() - start_time))\n",
    "\n",
    "!ls"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RetrainPSPNet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
