{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "LTGX0pl4YSuP",
    "outputId": "e932c5df-0063-45c9-95a4-da6c0932fb64"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Download dataset and models from google drive\n",
    "################################################################################\n",
    "\n",
    "!pip install PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "dataset_training = drive.CreateFile({'id': '1T3ekZdrQnPurftu-3jnoL-lu68ni4Fxh'})\n",
    "dataset_training.GetContentFile(\"dataset_training_0.zip\")\n",
    "\n",
    "dataset_validation = drive.CreateFile({'id': '1Hu4bm92fmnNNPlvweKUgdaPRkL_uN74Z'})\n",
    "dataset_validation.GetContentFile(\"dataset_validation_0.zip\")\n",
    "\n",
    "model = drive.CreateFile({'id': '1Ul5PTZ9S8CsuXEPEaLdngr_snClYvf9f'})\n",
    "model.GetContentFile(\"colorization_model.hdf5\")\n",
    "\n",
    "pspnet = drive.CreateFile({'id': '1oFuPmSbFqy_b8UPxNHNCMmYC99mogCEm'})\n",
    "pspnet.GetContentFile(\"pspnet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SnN1WJPxzVwR",
    "outputId": "2ce56d7f-b8ea-461f-8c9e-f46d8c12f74f"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Import libraries\n",
    "################################################################################\n",
    "\n",
    "import zipfile\n",
    "from PIL import Image, ImageFile\n",
    "from skimage.color import rgb2lab\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Conv2D, concatenate, Input, UpSampling2D\n",
    "from keras.callbacks import CSVLogger, Callback\n",
    "from keras.optimizers import Adam\n",
    "from keras import layers\n",
    "from keras.backend import tf as ktf\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C5ZF5CXJCefx"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Generator and its functions\n",
    "################################################################################\n",
    "\n",
    "# Returns normalized numpy arrays l, a and b (w x h x 1)\n",
    "def lab_img(img):\n",
    "    if img.format != (\"JPEG\" or \"JPG\"):\n",
    "        img = img.convert(\"RGB\")\n",
    "    \n",
    "    # convert to LAB\n",
    "    img = rgb2lab(img)\n",
    "\n",
    "    # split color chanels\n",
    "    l = img[:, :, 0]\n",
    "    a = img[:, :, 1]\n",
    "    b = img[:, :, 2]\n",
    "\n",
    "    # normalize\n",
    "    l = (np.array(l) / 100)\n",
    "    a = ((np.array(a) + 127) / 255) * 2 - 1\n",
    "    b = ((np.array(b) + 128) / 255) * 2 - 1\n",
    "\n",
    "    l = np.expand_dims(l, axis=2)\n",
    "    a = np.expand_dims(a, axis=2)\n",
    "    b = np.expand_dims(b, axis=2)\n",
    "\n",
    "    return l, a, b\n",
    "\n",
    "\n",
    "# Returns batches of x, y, and segmentation for training\n",
    "def batch_images(index, batch_size, images_size, image_paths, imgs, pspnet):\n",
    "    \n",
    "    # create empty batches\n",
    "    x_batch = np.zeros((batch_size, images_size[1], images_size[0], 1))\n",
    "    s_batch = np.zeros((batch_size, int(images_size[1] / 8), int(images_size[0] / 8), 150))\n",
    "    y_batch = np.zeros((batch_size, images_size[1], images_size[0], 2))\n",
    "    \n",
    "    # fill batches with images\n",
    "    for i in range(index, index + batch_size):\n",
    "        with imgs.open(image_paths[i]) as img:\n",
    "            img = Image.open(img)\n",
    "        \n",
    "        # randomly flip image\n",
    "        if random() < .5:\n",
    "            img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "        # create segmentation\n",
    "        s = predict_segmentation(img.convert(\"L\").convert(\"RGB\"), pspnet)\n",
    "        \n",
    "        # create x and y\n",
    "        l, a, b = lab_img(img, validation)\n",
    "        y = np.concatenate((a, b), axis=2)\n",
    "\n",
    "        x_batch[i - index] = l\n",
    "        s_batch[i - index] = s\n",
    "        y_batch[i - index] = y\n",
    "\n",
    "    return x_batch, s_batch, y_batch\n",
    "\n",
    "\n",
    "# Returns one-hot encoded segmentation object (w x h x 150)\n",
    "def predict_segmentation(img, pspnet):\n",
    "    data_mean = np.array([[[128, 128, 128]]])\n",
    "    input_size = (473, 473)\n",
    "    output_size = (img.size[0] / 8, img.size[1] / 8)\n",
    "\n",
    "    # resize to 473 x 473px\n",
    "    if img.size != input_size:\n",
    "        img = img.resize(input_size)\n",
    "\n",
    "    # normalize image\n",
    "    img = np.array(img)\n",
    "    img = img - data_mean\n",
    "    img = np.expand_dims(pixel_img, axis=0)\n",
    "    \n",
    "    # predict segmentation\n",
    "    segmentation = pspnet.predict(img)[0]\n",
    "    \n",
    "    # resize segmentation\n",
    "    if output_size != input_size:\n",
    "        segmentation = resize(segmentation,\n",
    "                             (output_size[1], output_size[0], 150),\n",
    "                              mode=\"constant\",\n",
    "                              preserve_range=True)\n",
    "    return segmentation\n",
    "\n",
    "\n",
    "# returns training batches\n",
    "def generator_fn(batch_size, images_path, images_size, pspnet):\n",
    "    with zipfile.ZipFile(images_path) as imgs:\n",
    "        image_paths = imgs.infolist()\n",
    "        n_images = len(image_paths)\n",
    "        i = 0\n",
    "        while True:\n",
    "            if i + batch_size > n_images:\n",
    "                i = 0\n",
    "            x, s, y = batch_images(i, batch_size, images_size, image_paths, imgs, pspnet, validation)\n",
    "            i += batch_size\n",
    "            yield [x, s], y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fkbmf3XdCW5V"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Loading, training and saving model\n",
    "################################################################################\n",
    "\n",
    "# custom pspnet layer\n",
    "class Interp(layers.Layer):\n",
    "\n",
    "    def __init__(self, new_size, **kwargs):\n",
    "        self.new_size = new_size\n",
    "        super(Interp, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Interp, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        new_height, new_width = self.new_size\n",
    "        resized = ktf.image.resize_images(inputs, [new_height, new_width],\n",
    "                                          align_corners=True)\n",
    "        return resized\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple([None, self.new_size[0], self.new_size[1], input_shape[3]])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Interp, self).get_config()\n",
    "        config['new_size'] = self.new_size\n",
    "        return config\n",
    "\n",
    "\n",
    "# Returns pspnet\n",
    "def load_pspnet(path):\n",
    "    pspnet = load_model(path, custom_objects={'Interp': Interp})\n",
    "    pspnet._make_predict_function()\n",
    "    return pspnet\n",
    "\n",
    "\n",
    "# Returns main model\n",
    "def model_definition():\n",
    "    grayscale_input = Input(shape=(None, None, 1))\n",
    "    grayscale1 = Conv2D(64, (5, 5), padding=\"same\", activation=\"relu\", strides=2)(grayscale_input)\n",
    "    grayscale2 = Conv2D(64, (5, 5), padding=\"same\", activation=\"relu\")(grayscale1)\n",
    "    grayscale3 = Conv2D(64, (5, 5), padding=\"same\", activation=\"relu\")(grayscale2)\n",
    "    r1 = layers.add([grayscale3, grayscale1])\n",
    "    grayscale4 = Conv2D(128, (5, 5), padding=\"same\", activation=\"relu\", strides=2)(r1)\n",
    "    grayscale5 = Conv2D(128, (5, 5), padding=\"same\", activation=\"relu\")(grayscale4)\n",
    "    grayscale6 = Conv2D(128, (5, 5), padding=\"same\", activation=\"relu\")(grayscale5)\n",
    "    r2 = layers.add([grayscale6, grayscale4])\n",
    "    grayscale7 = Conv2D(256, (5, 5), padding=\"same\", activation=\"relu\", strides=2)(r2)\n",
    "    grayscale8 = Conv2D(256, (5, 5), padding=\"same\", activation=\"relu\")(grayscale7)\n",
    "    grayscale9 = Conv2D(256, (5, 5), padding=\"same\", activation=\"relu\")(grayscale8)\n",
    "    r3 = layers.add([grayscale9, grayscale7])\n",
    "    grayscale10 = Conv2D(256, (5, 5), padding=\"same\", activation=\"relu\")(r3)\n",
    "    grayscale11 = Conv2D(256, (5, 5), padding=\"same\", activation=\"relu\")(grayscale10)\n",
    "    grayscale12 = Conv2D(256, (5, 5), padding=\"same\", activation=\"relu\")(grayscale11)\n",
    "    r4 = layers.add([grayscale12, grayscale10])\n",
    "\n",
    "    segmentation_input = Input(shape=(None, None, 150))\n",
    "\n",
    "    merged = concatenate([r4, segmentation_input], axis=3)\n",
    "    colorized1 = Conv2D(256, (5, 5), padding=\"same\", activation=\"relu\")(merged)\n",
    "    colorized2 = Conv2D(256, (5, 5), padding=\"same\", activation=\"relu\")(colorized1)\n",
    "    colorized3 = Conv2D(256, (5, 5), padding=\"same\", activation=\"relu\")(colorized2)\n",
    "    r4 = layers.add([colorized3, colorized1])\n",
    "    upsampling1 = UpSampling2D()(r4)\n",
    "    colorized4 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(upsampling1)\n",
    "    colorized5 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(colorized4)\n",
    "    colorized6 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(colorized5)\n",
    "    r5 = layers.add([colorized6, colorized4])\n",
    "    upsampling2 = UpSampling2D()(r5)\n",
    "    colorized7 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(upsampling2)\n",
    "    colorized8 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(colorized7)\n",
    "    colorized9 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(colorized8)\n",
    "    r6 = layers.add([colorized9, colorized7])\n",
    "    upsampling3 = UpSampling2D()(r6)\n",
    "    colorized10 = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(upsampling3)\n",
    "    colorized11 = Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\")(colorized10)\n",
    "    colorized12 = Conv2D(2, (3, 3), padding=\"same\", activation=\"tanh\")(colorized11)\n",
    "\n",
    "    model = Model(inputs=[grayscale_input, segmentation_input], outputs=colorized12)\n",
    "    model.compile(loss=\"mse\", optimizer=Adam(lr=0.00015, decay=0.035))\n",
    "    return model\n",
    "\n",
    "# Class for saving and uploading model & csv logger\n",
    "class save_and_upload(Callback):\n",
    "    def __init__(self, model_name, n_epochs):\n",
    "        self.model_name = model_name\n",
    "        self.n_epochs = n_epochs\n",
    "        self.model_checkpoint = drive.CreateFile({\"title\": self.model_name + \".hdf5\",\n",
    "                                              \"parents\": [{\"kind\": \"drive#childList\",\n",
    "                                                           \"id\": \"15svx5A7mYSLMrDcRDmgY5cB3Cj66m6j8\"}]})\n",
    "        self.model_log = drive.CreateFile({\"title\": self.model_name + \".csv\",\n",
    "                                        \"parents\": [{\"kind\": \"drive#childList\",\n",
    "                                                     \"id\": \"15svx5A7mYSLMrDcRDmgY5cB3Cj66m6j8\"}]})\n",
    "  \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        try:\n",
    "            if gauth.access_token_expired:\n",
    "                gauth.Refresh()\n",
    "        except:\n",
    "            print(\"refresh failed\")\n",
    "        if epoch / self.n_epochs > 0.4:\n",
    "            try:\n",
    "                self.model.save(self.model_name + \".hdf5\", overwrite=True)\n",
    "                self.model_checkpoint.SetContentFile(self.model_name + \".hdf5\")\n",
    "                self.model_log.SetContentFile(self.model_name + \".csv\")\n",
    "            except:\n",
    "                print(\"save failed\")\n",
    "\n",
    "            try:\n",
    "                self.model_checkpoint.Upload()\n",
    "                self.model_log.Upload()\n",
    "            except:\n",
    "                print(\"upload failed\")\n",
    "\n",
    "\n",
    "# Returns list of callbacks\n",
    "def callbacks(model_name, n_epochs):\n",
    "    cb = list()\n",
    "    cb.append(CSVLogger(model_name + \".csv\"))\n",
    "    cb.append(save_and_upload(model_name, n_epochs))\n",
    "    return cb\n",
    "\n",
    "\n",
    "# Trains the model\n",
    "def train_model(model, training_data_generator, validation_data_generator, n_epochs, steps_per_epoch, validation_steps, model_name):\n",
    "    model.fit_generator(training_data_generator,\n",
    "                        epochs=n_epochs,\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        callbacks=callbacks(model_name, n_epochs),\n",
    "                        validation_data=validation_data_generator,\n",
    "                        validation_steps=validation_steps,\n",
    "                        verbose=2,\n",
    "                        max_queue_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "nmkMHGMOCjLd",
    "outputId": "daca59d3-51e7-4fd0-8245-274a628c0018"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Main\n",
    "################################################################################\n",
    "\n",
    "model_name = \"Model_0\"\n",
    "batch_size = 64\n",
    "batches_per_epoch = 73\n",
    "n_epochs = 10\n",
    "batches_per_validation_epoch = 4\n",
    "images_size = (256, 256)\n",
    "\n",
    "pspnet = load_pspnet(\"pspnet.h5\")\n",
    "# model = model_definition()\n",
    "model = load_model(\"colorization_model.hdf5\")\n",
    "\n",
    "training_data_generator = generator_fn(batch_size, \"dataset2_training_0.zip\", images_size, pspnet)\n",
    "validation_data_generator = generator_fn(batch_size, \"dataset2_validation_0.zip\", images_size, pspnet)\n",
    "\n",
    "train_model(model, \n",
    "            training_data_generator, \n",
    "            validation_data_generator, \n",
    "            n_epochs, \n",
    "            batches_per_epoch, \n",
    "            batches_per_validation_epoch, \n",
    "            model_name)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "training_script.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
