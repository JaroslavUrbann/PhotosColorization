{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LTGX0pl4YSuP",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "ecc7a409-324e-4149-df59-9fc2e895a95f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adc.json  dataset.zip  model_checkpoint.hdf5  pspnet.h5  sample_data\n"
     ]
    }
   ],
   "source": [
    "###########################################################################################################\n",
    "# Download dataset and model from google drive to local storage\n",
    "###########################################################################################################\n",
    "\n",
    "!ls\n",
    "!pip install PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "dataset = drive.CreateFile({'id': '1g9FGP5mrqp1iki6PXwnUDD1Dq7EuNiW4'})\n",
    "dataset.GetContentFile(\"dataset.zip\")\n",
    "\n",
    "dataset = drive.CreateFile({'id': '1YpCm6bho9fNCVgY9Bh8WBaXX5OQlFqI1'})\n",
    "dataset.GetContentFile(\"pspnet.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SnN1WJPxzVwR",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "5340c5f0-93de-4f8b-bb9e-bbda0e21ecee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "###########################################################################################################\n",
    "# Import necessary libraries\n",
    "###########################################################################################################\n",
    "\n",
    "!pip install --upgrade keras\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2lab\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Conv2D, concatenate, Input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import layers\n",
    "from keras.backend import tf as ktf\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "C5ZF5CXJCefx",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "###########################################################################################################\n",
    "# Generator and its functions\n",
    "###########################################################################################################\n",
    "\n",
    "# Returns numpy arrays l, a and b (w x h x 1)\n",
    "def lab_img(img):\n",
    "    if img.format != (\"JPEG\" or \"JPG\"):\n",
    "        img = img.convert(\"RGB\")\n",
    "    img = rgb2lab(img)\n",
    "\n",
    "    l = img[:, :, 0]\n",
    "    a = img[:, :, 1]\n",
    "    b = img[:, :, 2]\n",
    "\n",
    "    l = np.array(l) / 100\n",
    "    a = (np.array(a) + 127) / 255\n",
    "    b = (np.array(b) + 128) / 255\n",
    "\n",
    "    l = np.expand_dims(l, axis=2)\n",
    "    a = np.expand_dims(a, axis=2)\n",
    "    b = np.expand_dims(b, axis=2)\n",
    "\n",
    "    return l, a, b\n",
    "\n",
    "\n",
    "# Returns batch of x and y values packed together\n",
    "def batch_images(index, batch_size, images_path, image_paths, trained_model):\n",
    "    with zipfile.ZipFile(images_path) as my_zip:\n",
    "        x_batch = []\n",
    "        s_batch = []\n",
    "        y_batch = []\n",
    "        start_position = index * batch_size\n",
    "        end_position = min(len(image_paths), index * batch_size + batch_size)\n",
    "        for image in range(start_position, end_position):\n",
    "            with my_zip.open(image_paths[image]) as img:\n",
    "                img = Image.open(img)\n",
    "                \n",
    "                s = predict_segmentation(img, trained_model)\n",
    "                l, a, b = lab_img(img)\n",
    "\n",
    "                y = np.concatenate((a, b), axis=2)\n",
    "\n",
    "                x_batch.append(l)\n",
    "                s_batch.append(s)\n",
    "                y_batch.append(y)\n",
    "\n",
    "                x = np.fliplr(l)\n",
    "                s = np.fliplr(s)\n",
    "                y = np.fliplr(y)\n",
    "\n",
    "                x_batch.append(x)\n",
    "                s_batch.append(s)\n",
    "                y_batch.append(y)\n",
    "\n",
    "        return x_batch, s_batch, y_batch\n",
    "\n",
    "\n",
    "# Returns one-hot encoded segmentation object (w x h x 150)\n",
    "def predict_segmentation(img, trained_model):\n",
    "    # TODO: do this in my model\n",
    "    data_mean = np.array([[[123.68, 116.779, 103.939]]])\n",
    "    image_size = img.size\n",
    "    input_size = (473, 473)\n",
    "\n",
    "    if image_size != input_size:\n",
    "        img = img.resize(input_size)\n",
    "\n",
    "    pixel_img = np.array(img)\n",
    "    pixel_img = pixel_img - data_mean\n",
    "    bgr_img = pixel_img[:, :, ::-1]\n",
    "    segmented_img = trained_model.predict(np.expand_dims(bgr_img, 0))[0]\n",
    "    if image_size != input_size:\n",
    "          segmented_img = resize(segmented_img, (image_size[1], image_size[0], 150), mode=\"constant\")\n",
    "    return segmented_img\n",
    "\n",
    "\n",
    "# Yields batches of x and y values\n",
    "def generator_fn(n_images, batch_size, images_path, trained_model):\n",
    "    with zipfile.ZipFile(images_path) as my_zip:\n",
    "        image_paths = my_zip.infolist()\n",
    "\n",
    "    batches_per_epoch = int(n_images / batch_size)\n",
    "\n",
    "    while True:\n",
    "        for i in range(batches_per_epoch):\n",
    "            x, s, y = batch_images(i, batch_size, images_path, image_paths, trained_model)\n",
    "            yield [np.array(x), np.array(s)], np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Fkbmf3XdCW5V",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "###########################################################################################################\n",
    "# Loading, training and saving model\n",
    "###########################################################################################################\n",
    "\n",
    "class Interp(layers.Layer):\n",
    "\n",
    "    def __init__(self, new_size, **kwargs):\n",
    "        self.new_size = new_size\n",
    "        super(Interp, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Interp, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        new_height, new_width = self.new_size\n",
    "        resized = ktf.image.resize_images(inputs, [new_height, new_width],\n",
    "                                          align_corners=True)\n",
    "        return resized\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple([None, self.new_size[0], self.new_size[1], input_shape[3]])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Interp, self).get_config()\n",
    "        config['new_size'] = self.new_size\n",
    "        return config\n",
    "\n",
    "\n",
    "# Returns trained model instance\n",
    "def load_trained_model(path):\n",
    "    trained_model = load_model(path, custom_objects={'Interp': Interp})\n",
    "    trained_model._make_predict_function()\n",
    "    return trained_model\n",
    "\n",
    "\n",
    "# Returns main model\n",
    "def model_definition():\n",
    "    grayscale_input = Input(shape=(None, None, 1))\n",
    "    grayscale = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", use_bias=True)(grayscale_input)\n",
    "    grayscale = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\", use_bias=True)(grayscale)\n",
    "    grayscale = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\", use_bias=True)(grayscale)\n",
    "\n",
    "    segmentation_input = Input(shape=(None, None, 150))\n",
    "    segmentation = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", use_bias=True)(segmentation_input)\n",
    "    segmentation = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\", use_bias=True)(segmentation)\n",
    "    segmentation = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\", use_bias=True)(segmentation)\n",
    "\n",
    "    merged = concatenate([grayscale, segmentation], axis=3)\n",
    "    colorized = Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", use_bias=True)(merged)\n",
    "    colorized = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\", use_bias=True)(colorized)\n",
    "    colorized = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", use_bias=True)(colorized)\n",
    "    colorized = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", use_bias=True)(colorized)\n",
    "    colorized = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", use_bias=True)(colorized)\n",
    "    colorized = Conv2D(2, (3, 3), padding=\"same\", activation=\"relu\", use_bias=True)(colorized)\n",
    "\n",
    "    model = Model(inputs=[grayscale_input, segmentation_input], outputs=colorized)\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Returns list of used keras callbacks\n",
    "def callbacks(model_path):\n",
    "    cb = list()\n",
    "    cb.append(ModelCheckpoint(os.path.join(model_path, \"model_checkpoint.hdf5\")))\n",
    "    return cb\n",
    "\n",
    "\n",
    "# Returns the model after training it\n",
    "def train_model(model, training_data_fn, validation_data_fn, epochs, steps_per_epoch, validation_steps, save_path):\n",
    "    model.fit_generator(training_data_fn,\n",
    "                        epochs=epochs,\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        callbacks=callbacks(save_path),\n",
    "                        validation_data=validation_data_fn,\n",
    "                        validation_steps=validation_steps,\n",
    "                        verbose=1)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nmkMHGMOCjLd",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153.0
    },
    "outputId": "68fc9397-f28b-41d1-fdc0-e8707e33179b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2/2 [==============================] - 58s 29s/step - loss: 0.2530 - val_loss: 0.2145\n",
      "Epoch 2/3\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.1686 - val_loss: 0.2015\n",
      "Epoch 3/3\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.1377 - val_loss: 0.1562\n",
      "Training took: 82.85155916213989\n",
      "adc.json  dataset.zip  model_checkpoint.hdf5  pspnet.h5  sample_data\n"
     ]
    }
   ],
   "source": [
    "###########################################################################################################\n",
    "# Control panel\n",
    "###########################################################################################################\n",
    "\n",
    "current_directory = \"\"\n",
    "\n",
    "n_images = 2\n",
    "batch_size = 1\n",
    "n_epochs = 3\n",
    "batches_per_epoch = int(n_images / batch_size)\n",
    "validation_batches = 1\n",
    "\n",
    "images_path = os.path.join(current_directory, \"dataset.zip\")\n",
    "trained_model_path = os.path.join(current_directory, \"pspnet.h5\")\n",
    "trained_model = load_trained_model(trained_model_path)\n",
    "\n",
    "training_data_fn = generator_fn(n_images, batch_size, images_path, trained_model)\n",
    "validation_data_fn = generator_fn(n_images, batch_size, images_path, trained_model)\n",
    "model = model_definition()\n",
    "start_time = time.time()\n",
    "train_model(model, \n",
    "            training_data_fn, \n",
    "            validation_data_fn, \n",
    "            n_epochs, \n",
    "            batches_per_epoch, \n",
    "            validation_batches, \n",
    "            current_directory)\n",
    "print(\"Training took: \" + str(time.time() - start_time))\n",
    "\n",
    "model_checkpoint = drive.CreateFile()\n",
    "model_checkpoint.SetContentFile(\"model_checkpoint.hdf5\")\n",
    "model_checkpoint.Upload()\n",
    "\n",
    "!ls\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
