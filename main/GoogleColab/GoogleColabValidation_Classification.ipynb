{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GoogleColabValidation_Classification.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"SnN1WJPxzVwR","colab_type":"code","outputId":"2bf1e622-df10-4b4a-b846-ea1b30b8816f","executionInfo":{"status":"ok","timestamp":1543752353505,"user_tz":-60,"elapsed":1667,"user":{"displayName":"Jaroslav Urban","photoUrl":"","userId":"14074859735195289022"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"cell_type":"code","source":["################################################################################\n","# Import necessary libraries\n","################################################################################\n","\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","import os\n","import random\n","from keras import layers\n","from keras.backend import tf as ktf\n","from keras.applications.mobilenet_v2 import MobileNetV2\n","from keras.models import load_model\n","import zipfile\n","from PIL import Image\n","from skimage.color import rgb2lab, lab2rgb\n","import numpy as np\n","from skimage.transform import resize\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from collections import namedtuple\n","import copy"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"C5ZF5CXJCefx","colab_type":"code","colab":{}},"cell_type":"code","source":["################################################################################\n","# Generator and its functions\n","################################################################################\n","\n","# Returns numpy arrays l, a and b (w x h x 1)\n","def lab_img(img):\n","    if img.format != (\"JPEG\" or \"JPG\"):\n","        img = img.convert(\"RGB\")\n","    img = rgb2lab(img)\n","\n","    l = img[:, :, 0]\n","\n","    l = (np.array(l) / 100)\n","\n","    l = np.expand_dims(l, axis=2)\n","\n","    return l\n","\n","\n","# Returns batch of x and y values packed together\n","def batch_images(image_path, imgs, trained_model):\n","    with imgs.open(image_path) as img:\n","        img = Image.open(img)\n","        w, h = img.size\n","        while w % 8 != 0:\n","            w += 1\n","        \n","        while h % 8 != 0:\n","            h += 1\n","        img = img.resize((w, h))\n","        \n","#         s = predict_segmentation(img.convert(\"L\").convert(\"RGB\"), trained_model)\n","        s = predict_classification(img.convert(\"L\").convert(\"RGB\"), trained_model)\n","        l = lab_img(img)\n","        return np.expand_dims(l, axis=0), np.expand_dims(s, axis=0)\n","\n","\n","# Returns one-hot encoded segmentation object (w x h x 150)\n","def predict_segmentation(img, trained_model):\n","    # TODO: do this in my model\n","    data_mean = np.array([[[123.68, 116.779, 103.939]]])\n","    input_size = (473, 473)\n","    output_size = (img.size[0] / 8, img.size[1] / 8)\n","\n","    if img.size != input_size:\n","        img = img.resize(input_size)\n","\n","    pixel_img = np.array(img)\n","    pixel_img = pixel_img - data_mean\n","    bgr_img = pixel_img[:, :, ::-1]\n","    segmented_img = trained_model.predict(np.expand_dims(bgr_img, 0))[0]\n","    if output_size != input_size:\n","          segmented_img = resize(segmented_img,\n","                                 (output_size[1], output_size[0], 150),\n","                                  mode=\"constant\",\n","                                  preserve_range=True)\n","    return segmented_img\n","  \n","  \n","def predict_classification(img, trained_model):\n","    classification_img = trained_model.predict(np.expand_dims(np.array(img), axis=0))[0]\n","    classification_img = resize(classification_img,\n","                               (img.size[1] / 8, img.size[0] / 8, 1280),\n","                               mode=\"constant\",\n","                               preserve_range=True)\n","    return classification_img\n","\n","\n","# Yields batches of x and y values\n","def generator_fn(n_images, images_path, trained_model):\n","    with zipfile.ZipFile(images_path) as imgs:\n","        image_paths = imgs.infolist()\n","        random.shuffle(image_paths)\n","        i = 0\n","        while True:\n","            if i == n_images:\n","                i = 0\n","            x, s = batch_images(image_paths[i], imgs, trained_model)\n","            i += 1\n","            yield x, s\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Fkbmf3XdCW5V","colab_type":"code","colab":{}},"cell_type":"code","source":["################################################################################\n","# Loading, training and saving model\n","################################################################################\n","\n","class Interp(layers.Layer):\n","\n","    def __init__(self, new_size, **kwargs):\n","        self.new_size = new_size\n","        super(Interp, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        super(Interp, self).build(input_shape)\n","\n","    def call(self, inputs, **kwargs):\n","        new_height, new_width = self.new_size\n","        resized = ktf.image.resize_images(inputs, [new_height, new_width],\n","                                          align_corners=True)\n","        return resized\n","\n","    def compute_output_shape(self, input_shape):\n","        return tuple([None, self.new_size[0], self.new_size[1], input_shape[3]])\n","\n","    def get_config(self):\n","        config = super(Interp, self).get_config()\n","        config['new_size'] = self.new_size\n","        return config\n","\n","\n","# Returns trained model instance\n","def load_trained_model(path):\n","    trained_model = load_model(path, custom_objects={'Interp': Interp})\n","    trained_model._make_predict_function()\n","    return trained_model\n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"NvucEav8_sWf","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","# Takes one instance of input and output (no batches)\n","def decode_images(l, s, y, save_path):\n","    global n_labels\n","    h, w, d = l.shape\n","    a, b = np.split(y[0], [1], 2)\n","    l = l[:, :, 0] * 100\n","    a = (a[:, :, 0] + 1) * 255 / 2 - 127\n","    b = (b[:, :, 0] + 1) * 255 / 2 - 128\n","\n","    # index to save the images under\n","    i = 0\n","    while os.path.isfile(os.path.join(save_path, str(i) + \"_input.jpg\")):\n","        i += 1\n","\n","    bnw_input = np.zeros((h, w, 3))\n","    bnw_input[:, :, 0] = l\n","    Image.fromarray((lab2rgb(bnw_input)*255).astype('uint8')).save(os.path.join(save_path, str(i) + \"_input.jpg\"))\n","\n","    color_output = np.zeros((h, w, 3))\n","    color_output[:, :, 0] = l\n","    color_output[:, :, 1] = a\n","    color_output[:, :, 2] = b\n","    Image.fromarray((lab2rgb(color_output)*255).astype('uint8')).save(os.path.join(save_path, str(i) + \"_output.jpg\"))\n","\n","    color_output = np.zeros((h, w, 3))\n","    color_output[:, :, 0] = np.full((h, w), 70)\n","    color_output[:, :, 1] = a\n","    color_output[:, :, 2] = b\n","    Image.fromarray((lab2rgb(color_output)*255).astype('uint8')).save(os.path.join(save_path, str(i) + \"_output_labels.jpg\"))\n","\n","\n","# visualizes images of first batch generated by generator_fn\n","def validate_images(n_images, model, generator_fn, save_path):\n","    for i in range(n_images):\n","        x, s = next(generator_fn)\n","        y = model.predict([x, s])\n","        print(i)\n","        decode_images(x[0], s[0], y, save_path)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nmkMHGMOCjLd","colab_type":"code","outputId":"b8ab4b65-aa56-4d15-a95a-7874ef8a6f1d","executionInfo":{"status":"ok","timestamp":1543752474370,"user_tz":-60,"elapsed":122508,"user":{"displayName":"Jaroslav Urban","photoUrl":"","userId":"14074859735195289022"}},"colab":{"base_uri":"https://localhost:8080/","height":363}},"cell_type":"code","source":["################################################################################\n","# Control panel\n","################################################################################\n","\n","n_images = 15\n","!mkdir drive/My\\ Drive/Validation/16th_gen\n","\n","images_path = \"drive/My Drive/Datasets/bw_test_dataset.zip\"\n","images_destination = \"drive/My Drive/Validation/16th_gen\"\n","# trained_model = load_trained_model(\"drive/My Drive/Checkpoints/pspnet.h5\")\n","trained_model = MobileNetV2(include_top=False)\n","colorization_model = load_model(\"drive/My Drive/Checkpoints/Models/16th_gen.hdf5\")\n","validation_data_fn = generator_fn(n_images, images_path, trained_model)\n","\n","validate_images(n_images, colorization_model, validation_data_fn, images_destination)\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet_v2.py:306: UserWarning: MobileNet shape is undefined. Weights for input shape(224, 224) will be loaded.\n","  warnings.warn('MobileNet shape is undefined.'\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","9412608/9406464 [==============================] - 0s 0us/step\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n"],"name":"stdout"}]}]}